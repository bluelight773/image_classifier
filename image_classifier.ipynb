{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refer to 01_intro.ipynb and 02_production.ipynb for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('data')\n",
    "\n",
    "# Our x are images, our y is a category. We'll resize all images initially to 128x128. The label for each image can be\n",
    "# determined from its parent folder. We'll apply an 80/20 training/validation split.\n",
    "faces = DataBlock(\n",
    "    blocks=(ImageBlock, CategoryBlock), \n",
    "    get_items=get_image_files, \n",
    "    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n",
    "    get_y=parent_label,\n",
    "    item_tfms=Resize(128))\n",
    "dls = faces.dataloaders(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.400627</td>\n",
       "      <td>0.638771</td>\n",
       "      <td>0.710145</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.636964</td>\n",
       "      <td>0.238934</td>\n",
       "      <td>0.884058</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.508803</td>\n",
       "      <td>0.250695</td>\n",
       "      <td>0.927536</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.390764</td>\n",
       "      <td>0.271932</td>\n",
       "      <td>0.942029</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.328277</td>\n",
       "      <td>0.264101</td>\n",
       "      <td>0.942029</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Finetune an Imagenet-trained resnet18 model where once epoch is run with the last layer unfrozen, then the rest of the\n",
    "# network is unfrozen for 4 epochs.\n",
    "learn = cnn_learner(dls, resnet18, metrics=accuracy)\n",
    "learn.fine_tune(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving the Model with Resizing and Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.066720</td>\n",
       "      <td>0.409224</td>\n",
       "      <td>0.840580</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.652061</td>\n",
       "      <td>0.315162</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.491158</td>\n",
       "      <td>0.309270</td>\n",
       "      <td>0.898551</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.380984</td>\n",
       "      <td>0.273859</td>\n",
       "      <td>0.927536</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.322465</td>\n",
       "      <td>0.270173</td>\n",
       "      <td>0.927536</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use random resized crop so a different part of the image is focused on with each epoch\n",
    "# Results are worse suggesting we're losing important data by cropping.\n",
    "faces = faces.new(item_tfms=RandomResizedCrop(128, min_scale=0.5))\n",
    "dls = faces.dataloaders(path)\n",
    "learn = cnn_learner(dls, resnet18, metrics=accuracy)\n",
    "learn.fine_tune(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.259792</td>\n",
       "      <td>0.517713</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.616555</td>\n",
       "      <td>0.402361</td>\n",
       "      <td>0.855072</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.457523</td>\n",
       "      <td>0.298578</td>\n",
       "      <td>0.898551</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.317921</td>\n",
       "      <td>0.251039</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.244738</td>\n",
       "      <td>0.246268</td>\n",
       "      <td>0.927536</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Since randomized crop produced worse result, we go with resizing with squishing/streteching allowed so\n",
    "# that we don't lose data and all pixels are represented in some way\n",
    "# We get an error rate similar to the original case\n",
    "faces = faces.new(item_tfms=Resize(128, ResizeMethod.Squish))\n",
    "dls = faces.dataloaders(path)\n",
    "learn = cnn_learner(dls, resnet18, metrics=accuracy)\n",
    "learn.fine_tune(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.371634</td>\n",
       "      <td>0.646815</td>\n",
       "      <td>0.753623</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.652111</td>\n",
       "      <td>0.452847</td>\n",
       "      <td>0.840580</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.571619</td>\n",
       "      <td>0.406979</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.443076</td>\n",
       "      <td>0.350106</td>\n",
       "      <td>0.855072</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.365055</td>\n",
       "      <td>0.301000</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Try data augmentation - Rotation, flipping, warping, brightness changes, contrast changes\n",
    "# Results declined\n",
    "faces = faces.new(item_tfms=Resize(128, ResizeMethod.Squish), batch_tfms=aug_transforms())\n",
    "dls = faces.dataloaders(path)\n",
    "learn = cnn_learner(dls, resnet18, metrics=accuracy)\n",
    "learn.fine_tune(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.202318</td>\n",
       "      <td>0.369461</td>\n",
       "      <td>0.884058</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.677587</td>\n",
       "      <td>0.214881</td>\n",
       "      <td>0.898551</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.594762</td>\n",
       "      <td>0.149296</td>\n",
       "      <td>0.942029</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.488187</td>\n",
       "      <td>0.173700</td>\n",
       "      <td>0.927536</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.413810</td>\n",
       "      <td>0.168024</td>\n",
       "      <td>0.927536</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Since squishing wasn't clearly better than a normal resize, we try a normal resize along with\n",
    "# augmentation.\n",
    "# We get 93% accuracy\n",
    "faces = faces.new(item_tfms=Resize(128), batch_tfms=aug_transforms())\n",
    "dls = faces.dataloaders(path)\n",
    "learn = cnn_learner(dls, resnet18, metrics=accuracy)\n",
    "learn.fine_tune(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.360550</td>\n",
       "      <td>0.653013</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bluelight/envs/image_classifier_env/lib/python3.6/site-packages/PIL/Image.py:961: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.303443</td>\n",
       "      <td>0.286775</td>\n",
       "      <td>0.912000</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.221343</td>\n",
       "      <td>0.165196</td>\n",
       "      <td>0.952000</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.162086</td>\n",
       "      <td>0.126161</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.131050</td>\n",
       "      <td>0.133373</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bluelight/envs/image_classifier_env/lib/python3.6/site-packages/PIL/Image.py:961: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/home/bluelight/envs/image_classifier_env/lib/python3.6/site-packages/PIL/Image.py:961: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/home/bluelight/envs/image_classifier_env/lib/python3.6/site-packages/PIL/Image.py:961: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/home/bluelight/envs/image_classifier_env/lib/python3.6/site-packages/PIL/Image.py:961: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    }
   ],
   "source": [
    "# We return to using squish resizing so full data is included. But this time we use a deeper network as well.\n",
    "# Resnet model we could use are: resnet18, resnet34, resnet50, resnet101, resnet152\n",
    "# resnet34 produces slightly worse results\n",
    "faces = faces.new(item_tfms=Resize(128, ResizeMethod.Squish), batch_tfms=aug_transforms())\n",
    "dls = faces.dataloaders(path)\n",
    "# We reduce the batch-size to ensure the model can be trained on the GPU\n",
    "learn = cnn_learner(dls, resnet34, metrics=accuracy, bs=32)\n",
    "learn.fine_tune(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.235793</td>\n",
       "      <td>0.827627</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.700897</td>\n",
       "      <td>0.210412</td>\n",
       "      <td>0.898551</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.581560</td>\n",
       "      <td>0.126296</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.463669</td>\n",
       "      <td>0.133857</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.396687</td>\n",
       "      <td>0.146669</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We return to using the model producing the best results after 2 epochs where a normal resize\n",
    "# and augmentation transforms are applied\n",
    "# This time, we also use set_seed to get reproducible results\n",
    "set_seed(42, True)\n",
    "faces = faces.new(item_tfms=Resize(128), batch_tfms=aug_transforms())\n",
    "dls = faces.dataloaders(path)\n",
    "learn = cnn_learner(dls, resnet18, metrics=accuracy)\n",
    "learn.fine_tune(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68d5e5beef1e4bbbb0ed16e9179ffd6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(options=('female', 'male'), value='female'), Dropdown(options=('Train', 'Valid'), valu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Can show some images, select which ones to delete, then run the deletion code in the cell below\n",
    "from fastai.vision.widgets import *\n",
    "cleaner = ImageClassifierCleaner(learn)\n",
    "cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once we've selected images to delete, run the line below to have them deleted\n",
    "for idx in cleaner.delete(): cleaner.fns[idx].unlink()\n",
    "\n",
    "# This line takes care of moving images between categories\n",
    "for idx,cat in cleaner.change(): shutil.move(str(cleaner.fns[idx]), path/cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.235793</td>\n",
       "      <td>0.827627</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.700897</td>\n",
       "      <td>0.210412</td>\n",
       "      <td>0.898551</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.581560</td>\n",
       "      <td>0.126296</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.463669</td>\n",
       "      <td>0.133857</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.396687</td>\n",
       "      <td>0.146669</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We return to using the model producing the best results where a normal resize\n",
    "# and augmentation transforms are applied\n",
    "# This time, we have cleaner data as well. We get 96% error after all epochs though 97% after the 2nd and 3rd epoch.\n",
    "set_seed(42, True)\n",
    "faces = faces.new(item_tfms=Resize(128), batch_tfms=aug_transforms())\n",
    "dls = faces.dataloaders(path)\n",
    "learn = cnn_learner(dls, resnet18, metrics=accuracy)\n",
    "learn.fine_tune(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: (#2) ['female','male']\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: male\n"
     ]
    }
   ],
   "source": [
    "# Save model\n",
    "model_path = Path(\"models\")/\"male_vs_female_face_classifier.pkl\"\n",
    "learn.export(model_path)\n",
    "\n",
    "# Load and use the model\n",
    "learn_inf = load_learner(model_path)\n",
    "print(\"Classes:\", learn_inf.dls.vocab)\n",
    "predicted_class, predicted_class_index, pred_probs = learn_inf.predict(\"data/male/image.jpeg\")\n",
    "print(\"Predicted Class:\", predicted_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treating as a MultiLabel Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('data')\n",
    "\n",
    "# Ensure reproducibility of results\n",
    "set_seed(42, True)\n",
    "\n",
    "# To treat the problem as a multilabel classification problem, we provide y as a list\n",
    "# indicating all the applicable categories, if any.\n",
    "def get_y_labels(file):\n",
    "    return [parent_label(file)]\n",
    "\n",
    "faces = DataBlock(\n",
    "    blocks=(ImageBlock, MultiCategoryBlock), \n",
    "    get_items=get_image_files, \n",
    "    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n",
    "    get_y=get_y_labels,\n",
    "    item_tfms=Resize(128), batch_tfms=aug_transforms())\n",
    "\n",
    "dls = faces.dataloaders(path)\n",
    "\n",
    "# We use multi-accuracy which computes the accuracy rate across labels\n",
    "learn = cnn_learner(dls, resnet18, metrics=accuracy_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fine_tune(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ensure reproducibility of results\n",
    "set_seed(42, True)\n",
    "\n",
    "# Identify an optimal learning rate - use the steep learning rate\n",
    "lr_candidates = learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.00363078061491251, 0.003, 0.0014454397559165953, 0.001)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " lr_candidates.lr_steep, lr_candidates.lr_min/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy_multi</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.886078</td>\n",
       "      <td>0.708721</td>\n",
       "      <td>0.725490</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy_multi</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.495140</td>\n",
       "      <td>0.370487</td>\n",
       "      <td>0.840336</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.422499</td>\n",
       "      <td>0.215489</td>\n",
       "      <td>0.913165</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.365326</td>\n",
       "      <td>0.177833</td>\n",
       "      <td>0.929972</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.320023</td>\n",
       "      <td>0.168760</td>\n",
       "      <td>0.938375</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train and Save model LR-optimized model\n",
    "\n",
    "# Ensure reproducibility of results\n",
    "set_seed(42, True)\n",
    "# learn.fine_tune(4, lr_candidates.lr_steep)\n",
    "learn.fine_tune(4, 1e-3)\n",
    "model_path = Path(\"models\")/\"male_vs_female_face_classifier.pkl\"\n",
    "learn.export(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: (#3) ['female','male','misc']\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Labels: (#1) ['male']\n"
     ]
    }
   ],
   "source": [
    "# Load and use the model\n",
    "model_path = Path(\"models\")/\"male_vs_female_face_classifier.pkl\"\n",
    "learn_inf = load_learner(model_path)\n",
    "print(\"Labels:\", learn_inf.dls.vocab)\n",
    "predicted_labels, predicted_label_mask, pred_probs = learn_inf.predict(\"data/male/image.jpeg\")\n",
    "print(\"Predicted Labels:\", predicted_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
